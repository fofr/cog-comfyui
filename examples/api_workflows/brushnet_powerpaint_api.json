{
  "12": {
    "inputs": {
      "images": [
        "54",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "45": {
    "inputs": {
      "brushnet": "powerpaint_v2.1.safetensors",
      "dtype": "float16"
    },
    "class_type": "BrushNetLoader",
    "_meta": {
      "title": "BrushNet Loader"
    }
  },
  "47": {
    "inputs": {
      "ckpt_name": "juggernaut_reborn.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "49": {
    "inputs": {
      "text": "empty scene blur",
      "clip": [
        "47",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "50": {
    "inputs": {
      "text": "",
      "clip": [
        "47",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "52": {
    "inputs": {
      "seed": 0,
      "steps": 20,
      "cfg": 7.5,
      "sampler_name": "euler",
      "scheduler": "normal",
      "denoise": 1,
      "model": [
        "65",
        0
      ],
      "positive": [
        "65",
        1
      ],
      "negative": [
        "65",
        2
      ],
      "latent_image": [
        "65",
        3
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "54": {
    "inputs": {
      "samples": [
        "52",
        0
      ],
      "vae": [
        "47",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "58": {
    "inputs": {
      "image": "https://replicate.delivery/xezq/acQsSCLoTPpFLBJjoo2ueLIflEA9XAGFqi0X1Y8A33n2zM9TA/out-0.webp",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "65": {
    "inputs": {
      "fitting": 1,
      "function": "object removal",
      "scale": 1,
      "start_at": 0,
      "end_at": 10000,
      "save_memory": "none",
      "model": [
        "47",
        0
      ],
      "vae": [
        "47",
        2
      ],
      "image": [
        "58",
        0
      ],
      "mask": [
        "75",
        1
      ],
      "powerpaint": [
        "45",
        0
      ],
      "clip": [
        "66",
        0
      ],
      "positive": [
        "49",
        0
      ],
      "negative": [
        "50",
        0
      ]
    },
    "class_type": "PowerPaint",
    "_meta": {
      "title": "PowerPaint"
    }
  },
  "66": {
    "inputs": {
      "base": "sd15/model.safetensors",
      "powerpaint": "powerpaint_v2.1_pytorch_model.bin"
    },
    "class_type": "PowerPaintCLIPLoader",
    "_meta": {
      "title": "PowerPaint CLIP Loader"
    }
  },
  "74": {
    "inputs": {
      "model_name": "GroundingDINO_SwinT_OGC (694MB)"
    },
    "class_type": "GroundingDinoModelLoader (segment anything)",
    "_meta": {
      "title": "GroundingDinoModelLoader (segment anything)"
    }
  },
  "75": {
    "inputs": {
      "prompt": "leaves",
      "threshold": 0.3,
      "sam_model": [
        "76",
        0
      ],
      "grounding_dino_model": [
        "74",
        0
      ],
      "image": [
        "58",
        0
      ]
    },
    "class_type": "GroundingDinoSAMSegment (segment anything)",
    "_meta": {
      "title": "GroundingDinoSAMSegment (segment anything)"
    }
  },
  "76": {
    "inputs": {
      "model_name": "sam_vit_h (2.56GB)"
    },
    "class_type": "SAMModelLoader (segment anything)",
    "_meta": {
      "title": "SAMModelLoader (segment anything)"
    }
  }
}
